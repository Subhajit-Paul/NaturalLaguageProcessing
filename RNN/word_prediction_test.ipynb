{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eefdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import string\n",
    "import joblib\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding, Dropout\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import joblib\n",
    "from numpy import array\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4962c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'text', encoding='utf8') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef6733",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[0:10000000].split(\" \")\n",
    "data = data[20000:20050]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9d4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"oov\")\n",
    "tokenizer.fit_on_texts([data])\n",
    "\n",
    "joblib.dump(tokenizer, 'tokenizer_of_text')\n",
    "\n",
    "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "sequences = []\n",
    "\n",
    "for i in range(1, len(sequence_data)):\n",
    "    words = sequence_data[i-1:i+1]\n",
    "    sequences.append(words)\n",
    "    \n",
    "sequences = np.array(sequences)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in sequences:\n",
    "    X.append(i[0])\n",
    "    y.append(i[1])\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7302d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=1))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba2dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model_check_1.h5\", monitor='loss', verbose=1,\n",
    "    save_best_only=True, mode='auto')\n",
    "\n",
    "reduce = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=1, min_lr=0.000001, verbose = 1)\n",
    "\n",
    "logdir='logsnextword1'\n",
    "tensorboard_Visualization = TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5855cb12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer = tensorflow.keras.optimizers.Adam(learning_rate=0.00001))\n",
    "model.fit(X, y, epochs=600, batch_size=2, callbacks=[checkpoint, reduce, tensorboard_Visualization])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow.keras.models.save_model(model, r'FINALMODEL_FOR_TEST.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c768e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved = tensorflow.keras.models.load_model(r'FINALMODEL_FOR_TEST.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1adb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = joblib.load(r'tokenizer_of_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c1068",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\Subhajit Paul\\Downloads\\lg model\\model.txt', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open(r'C:\\Users\\Subhajit Paul\\Downloads\\lg model\\tokenizer', 'r') as t:\n",
    "    tokenizer = t.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d73222a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
